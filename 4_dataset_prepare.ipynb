{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f152b0d",
   "metadata": {},
   "source": [
    "Classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b205b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aba606",
   "metadata": {},
   "source": [
    "Combining the Padel Descriptor output for the DNA gyrase inhibitor and decoy molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d511edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>...</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOGEN_smiles_1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.1766</td>\n",
       "      <td>4.737588</td>\n",
       "      <td>66.8370</td>\n",
       "      <td>53.407653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>7.662735</td>\n",
       "      <td>53.423678</td>\n",
       "      <td>2.054757</td>\n",
       "      <td>19.603698</td>\n",
       "      <td>9.973243</td>\n",
       "      <td>7.028501</td>\n",
       "      <td>1484</td>\n",
       "      <td>51</td>\n",
       "      <td>1.832</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOGEN_smiles_2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.3013</td>\n",
       "      <td>1.693382</td>\n",
       "      <td>59.4132</td>\n",
       "      <td>53.407653</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>7.662735</td>\n",
       "      <td>53.423678</td>\n",
       "      <td>2.054757</td>\n",
       "      <td>19.603698</td>\n",
       "      <td>9.973243</td>\n",
       "      <td>7.028501</td>\n",
       "      <td>1484</td>\n",
       "      <td>51</td>\n",
       "      <td>1.809</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTOGEN_smiles_3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0135</td>\n",
       "      <td>1.027182</td>\n",
       "      <td>52.4994</td>\n",
       "      <td>48.185274</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>7.884124</td>\n",
       "      <td>49.016084</td>\n",
       "      <td>2.042337</td>\n",
       "      <td>19.968336</td>\n",
       "      <td>7.434296</td>\n",
       "      <td>9.945672</td>\n",
       "      <td>1234</td>\n",
       "      <td>43</td>\n",
       "      <td>1.267</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTOGEN_smiles_4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0321</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>59.1725</td>\n",
       "      <td>47.965688</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>8.740818</td>\n",
       "      <td>52.412431</td>\n",
       "      <td>2.015863</td>\n",
       "      <td>25.240393</td>\n",
       "      <td>7.433893</td>\n",
       "      <td>10.157549</td>\n",
       "      <td>1537</td>\n",
       "      <td>48</td>\n",
       "      <td>2.134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOGEN_smiles_5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0321</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>59.1725</td>\n",
       "      <td>47.965688</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>8.740818</td>\n",
       "      <td>52.412431</td>\n",
       "      <td>2.015863</td>\n",
       "      <td>25.240393</td>\n",
       "      <td>7.433893</td>\n",
       "      <td>10.157549</td>\n",
       "      <td>1537</td>\n",
       "      <td>48</td>\n",
       "      <td>2.134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ZINC000000001534</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.9487</td>\n",
       "      <td>3.797432</td>\n",
       "      <td>32.2822</td>\n",
       "      <td>52.309825</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6.113082</td>\n",
       "      <td>43.233659</td>\n",
       "      <td>2.058746</td>\n",
       "      <td>6.890752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.890752</td>\n",
       "      <td>981</td>\n",
       "      <td>25</td>\n",
       "      <td>5.714</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>ZINC000000001536</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1368</td>\n",
       "      <td>1.292314</td>\n",
       "      <td>34.9328</td>\n",
       "      <td>45.286274</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.003439</td>\n",
       "      <td>40.076299</td>\n",
       "      <td>2.003815</td>\n",
       "      <td>5.116616</td>\n",
       "      <td>5.116616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>828</td>\n",
       "      <td>30</td>\n",
       "      <td>5.024</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>ZINC000000001553</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.6576</td>\n",
       "      <td>0.432438</td>\n",
       "      <td>26.0410</td>\n",
       "      <td>36.083516</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.003370</td>\n",
       "      <td>37.127417</td>\n",
       "      <td>2.062634</td>\n",
       "      <td>14.996255</td>\n",
       "      <td>2.524096</td>\n",
       "      <td>12.472159</td>\n",
       "      <td>660</td>\n",
       "      <td>24</td>\n",
       "      <td>1.973</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>ZINC000000001557</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3141</td>\n",
       "      <td>0.098659</td>\n",
       "      <td>38.3032</td>\n",
       "      <td>52.445032</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>6.438888</td>\n",
       "      <td>45.041651</td>\n",
       "      <td>2.047348</td>\n",
       "      <td>9.157403</td>\n",
       "      <td>2.359417</td>\n",
       "      <td>6.797986</td>\n",
       "      <td>1007</td>\n",
       "      <td>36</td>\n",
       "      <td>4.563</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>ZINC000000001569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.024025</td>\n",
       "      <td>21.2329</td>\n",
       "      <td>42.625895</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.574579</td>\n",
       "      <td>40.915826</td>\n",
       "      <td>2.045791</td>\n",
       "      <td>8.734972</td>\n",
       "      <td>5.736959</td>\n",
       "      <td>2.998012</td>\n",
       "      <td>748</td>\n",
       "      <td>32</td>\n",
       "      <td>4.017</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952 rows × 1445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  nAcid   ALogP    ALogp2      AMR       apol  \\\n",
       "0    AUTOGEN_smiles_1      1 -2.1766  4.737588  66.8370  53.407653   \n",
       "1    AUTOGEN_smiles_2      1 -1.3013  1.693382  59.4132  53.407653   \n",
       "2    AUTOGEN_smiles_3      1 -1.0135  1.027182  52.4994  48.185274   \n",
       "3    AUTOGEN_smiles_4      1 -0.0321  0.001030  59.1725  47.965688   \n",
       "4    AUTOGEN_smiles_5      1 -0.0321  0.001030  59.1725  47.965688   \n",
       "..                ...    ...     ...       ...      ...        ...   \n",
       "947  ZINC000000001534      0 -1.9487  3.797432  32.2822  52.309825   \n",
       "948  ZINC000000001536      0  1.1368  1.292314  34.9328  45.286274   \n",
       "949  ZINC000000001553      0 -0.6576  0.432438  26.0410  36.083516   \n",
       "950  ZINC000000001557      0 -0.3141  0.098659  38.3032  52.445032   \n",
       "951  ZINC000000001569      0  0.1550  0.024025  21.2329  42.625895   \n",
       "\n",
       "     naAromAtom  nAromBond  nAtom  nHeavyAtom  ...       AMW     WTPT-1  \\\n",
       "0             0          0     47          26  ...  7.662735  53.423678   \n",
       "1             6          6     47          26  ...  7.662735  53.423678   \n",
       "2             6          6     42          24  ...  7.884124  49.016084   \n",
       "3             6          6     42          26  ...  8.740818  52.412431   \n",
       "4             6          6     42          26  ...  8.740818  52.412431   \n",
       "..          ...        ...    ...         ...  ...       ...        ...   \n",
       "947          12         12     46          21  ...  6.113082  43.233659   \n",
       "948          12         13     38          20  ...  7.003439  40.076299   \n",
       "949          11         12     30          18  ...  8.003370  37.127417   \n",
       "950          12         12     46          22  ...  6.438888  45.041651   \n",
       "951          15         16     35          20  ...  7.574579  40.915826   \n",
       "\n",
       "       WTPT-2     WTPT-3    WTPT-4     WTPT-5  WPATH  WPOL  XLogP  Zagreb  \n",
       "0    2.054757  19.603698  9.973243   7.028501   1484    51  1.832     146  \n",
       "1    2.054757  19.603698  9.973243   7.028501   1484    51  1.809     146  \n",
       "2    2.042337  19.968336  7.434296   9.945672   1234    43  1.267     134  \n",
       "3    2.015863  25.240393  7.433893  10.157549   1537    48  2.134     138  \n",
       "4    2.015863  25.240393  7.433893  10.157549   1537    48  2.134     138  \n",
       "..        ...        ...       ...        ...    ...   ...    ...     ...  \n",
       "947  2.058746   6.890752  0.000000   6.890752    981    25  5.714     104  \n",
       "948  2.003815   5.116616  5.116616   0.000000    828    30  5.024      98  \n",
       "949  2.062634  14.996255  2.524096  12.472159    660    24  1.973      94  \n",
       "950  2.047348   9.157403  2.359417   6.797986   1007    36  4.563     116  \n",
       "951  2.045791   8.734972  5.736959   2.998012    748    32  4.017     106  \n",
       "\n",
       "[952 rows x 1445 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =pd.read_csv(r\"C:\\Users\\saman\\Desktop\\Gyrase\\smiles\\smiles_padel.csv\")\n",
    "df2= pd.read_csv(r\"C:\\Users\\saman\\Desktop\\Gyrase\\decoys\\decoy_padel.csv\")\n",
    "df= pd.concat([df1, df2], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092d3ad",
   "metadata": {},
   "source": [
    "Assigning labels to the dataframe:  ZINC = decoy(0)\n",
    "AUTOGEN_ = active(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b760213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saman\\AppData\\Local\\Temp\\ipykernel_17544\\4236325685.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Label'] = df['name'].apply(lambda x: 0 if 'ZINC' in x else 1)\n"
     ]
    }
   ],
   "source": [
    "df['Label'] = df['name'].apply(lambda x: 0 if 'ZINC' in x else 1)\n",
    "df.to_csv(\"labeled_descriptor.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696e042",
   "metadata": {},
   "source": [
    "Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc5fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean= df.drop(columns=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916b3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean =df_clean.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29094124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove low variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X = df_clean.drop(columns=[\"Label\"])\n",
    "y = df_clean[\"Label\"]\n",
    "\n",
    "X_lowvar = selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611d3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove highly correlated features\n",
    "import numpy as np\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = pd.DataFrame(X_lowvar).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop features with correlation > 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "X_filtered = pd.DataFrame(X_lowvar).drop(columns=to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75660cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1e1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfe27a",
   "metadata": {},
   "source": [
    "Training Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac3f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Initialize models\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"Support Vector Machine\": svm,\n",
    "    \"XGBoost\": xgb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df7ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest ---\n",
      "Confusion Matrix:\n",
      "[[ 80   1]\n",
      " [  6 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        81\n",
      "           1       0.99      0.95      0.97       110\n",
      "\n",
      "    accuracy                           0.96       191\n",
      "   macro avg       0.96      0.97      0.96       191\n",
      "weighted avg       0.96      0.96      0.96       191\n",
      "\n",
      "ROC AUC Score: 0.9965\n",
      "\n",
      "--- Support Vector Machine ---\n",
      "Confusion Matrix:\n",
      "[[ 81   0]\n",
      " [  6 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        81\n",
      "           1       1.00      0.95      0.97       110\n",
      "\n",
      "    accuracy                           0.97       191\n",
      "   macro avg       0.97      0.97      0.97       191\n",
      "weighted avg       0.97      0.97      0.97       191\n",
      "\n",
      "ROC AUC Score: 0.9955\n",
      "\n",
      "--- XGBoost ---\n",
      "Confusion Matrix:\n",
      "[[ 80   1]\n",
      " [  4 106]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        81\n",
      "           1       0.99      0.96      0.98       110\n",
      "\n",
      "    accuracy                           0.97       191\n",
      "   macro avg       0.97      0.98      0.97       191\n",
      "weighted avg       0.97      0.97      0.97       191\n",
      "\n",
      "ROC AUC Score: 0.9954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b4f",
   "metadata": {},
   "source": [
    "Model | Accuracy | ROC AUC | Notes\n",
    "1) Random Forest | 97% | 0.9993 | Near perfect\n",
    "2) SVM (RBF kernel) | 97% | 0.9972 | Excellent\n",
    "3) XGBoost | 100% | 1.0000 | Perfect fit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7475266b",
   "metadata": {},
   "source": [
    "Cross Validating with ROC AUC tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f4822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC (5-Fold CV): nan ± nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM AUC (5-Fold CV): nan ± nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUC (5-Fold CV): nan ± nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 194, in wrapper\n",
      "    params = func_sig.bind(*args, **kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3045, in bind\n",
      "    return self._bind(args, kwargs)\n",
      "  File \"c:\\Users\\saman\\Miniconda3\\envs\\bioenv\\lib\\inspect.py\", line 3034, in _bind\n",
      "    raise TypeError(\n",
      "TypeError: got an unexpected keyword argument 'needs_proba'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Create Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Custom scorer for ROC AUC\n",
    "roc_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"SVM\": svm,\n",
    "    \"XGBoost\": xgb\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=skf, scoring=roc_auc)\n",
    "    print(f\"{name} AUC (5-Fold CV): {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aea45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AUC scoring (requires predict_proba)\n",
    "scoring = 'roc_auc'  # for binary classification\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(probability=True)  # This enables predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "425d3a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC (5-Fold CV): 0.99 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"Random Forest AUC (5-Fold CV): {scores.mean():.2f} ± {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ffecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5267676767676768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "dummy.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, dummy.predict_proba(X_test)[:, 1])  # Should be ~0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58324d",
   "metadata": {},
   "source": [
    "Since our DummyClassifier indicates the model is only performing slightly better than random guessing. The score is very close to 0.5 ehich indicates random guessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4553e8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns: Index([], dtype='object')\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate columns\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "print(\"Duplicate columns:\", duplicate_columns)\n",
    "print(\"Number of duplicate rows:\", len(duplicate_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ab96770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns with high correlation: ['nAcid', 'ALogP', 'ALogp2', 'AMR', 'apol', 'naAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', 'nH', 'nC', 'nN', 'nO', 'nS', 'nP', 'nF', 'nCl', 'nBr', 'nI', 'nX', 'ATS0m', 'ATS1m', 'ATS2m', 'ATS3m', 'ATS4m', 'ATS5m', 'ATS6m', 'ATS7m', 'ATS8m', 'ATS0v', 'ATS1v', 'ATS2v', 'ATS3v', 'ATS4v', 'ATS5v', 'ATS6v', 'ATS7v', 'ATS8v', 'ATS0e', 'ATS1e', 'ATS2e', 'ATS3e', 'ATS4e', 'ATS5e', 'ATS6e', 'ATS7e', 'ATS8e', 'ATS0p', 'ATS1p', 'ATS2p', 'ATS3p', 'ATS4p', 'ATS5p', 'ATS6p', 'ATS7p', 'ATS8p', 'ATS0i', 'ATS1i', 'ATS2i', 'ATS3i', 'ATS4i', 'ATS5i', 'ATS6i', 'ATS7i', 'ATS8i', 'ATS0s', 'ATS1s', 'ATS2s', 'ATS3s', 'ATS4s', 'ATS5s', 'ATS6s', 'ATS7s', 'ATS8s', 'AATS0m', 'AATS1m', 'AATS2m', 'AATS3m', 'AATS4m', 'AATS5m', 'AATS6m', 'AATS7m', 'AATS8m', 'AATS0v', 'AATS1v', 'AATS2v', 'AATS3v', 'AATS4v', 'AATS5v', 'AATS6v', 'AATS7v', 'AATS8v', 'AATS0e', 'AATS1e', 'AATS2e', 'AATS3e', 'AATS4e', 'AATS5e', 'AATS6e', 'AATS7e', 'AATS8e', 'AATS0p', 'AATS1p', 'AATS2p', 'AATS3p', 'AATS4p', 'AATS5p', 'AATS6p', 'AATS7p', 'AATS8p', 'AATS0i', 'AATS1i', 'AATS2i', 'AATS3i', 'AATS4i', 'AATS5i', 'AATS6i', 'AATS7i', 'AATS8i', 'AATS0s', 'AATS1s', 'AATS2s', 'AATS3s', 'AATS4s', 'AATS5s', 'AATS6s', 'AATS7s', 'AATS8s', 'ATSC0c', 'ATSC1c', 'ATSC2c', 'ATSC3c', 'ATSC4c', 'ATSC5c', 'ATSC6c', 'ATSC7c', 'ATSC8c', 'ATSC0m', 'ATSC1m', 'ATSC2m', 'ATSC3m', 'ATSC4m', 'ATSC5m', 'ATSC6m', 'ATSC7m', 'ATSC8m', 'ATSC0v', 'ATSC1v', 'ATSC2v', 'ATSC3v', 'ATSC4v', 'ATSC5v', 'ATSC6v', 'ATSC7v', 'ATSC8v', 'ATSC0e', 'ATSC1e', 'ATSC2e', 'ATSC3e', 'ATSC4e', 'ATSC5e', 'ATSC6e', 'ATSC7e', 'ATSC8e', 'ATSC0p', 'ATSC1p', 'ATSC2p', 'ATSC3p', 'ATSC4p', 'ATSC5p', 'ATSC6p', 'ATSC7p', 'ATSC8p', 'ATSC0i', 'ATSC1i', 'ATSC2i', 'ATSC3i', 'ATSC4i', 'ATSC5i', 'ATSC6i', 'ATSC7i', 'ATSC8i', 'ATSC0s', 'ATSC1s', 'ATSC2s', 'ATSC3s', 'ATSC4s', 'ATSC5s', 'ATSC6s', 'ATSC7s', 'ATSC8s', 'AATSC0c', 'AATSC1c', 'AATSC2c', 'AATSC3c', 'AATSC4c', 'AATSC5c', 'AATSC6c', 'AATSC7c', 'AATSC8c', 'AATSC0m', 'AATSC1m', 'AATSC2m', 'AATSC3m', 'AATSC4m', 'AATSC5m', 'AATSC6m', 'AATSC7m', 'AATSC8m', 'AATSC0v', 'AATSC1v', 'AATSC2v', 'AATSC3v', 'AATSC4v', 'AATSC5v', 'AATSC6v', 'AATSC7v', 'AATSC8v', 'AATSC0e', 'AATSC1e', 'AATSC2e', 'AATSC3e', 'AATSC4e', 'AATSC5e', 'AATSC6e', 'AATSC7e', 'AATSC8e', 'AATSC0p', 'AATSC1p', 'AATSC2p', 'AATSC3p', 'AATSC4p', 'AATSC5p', 'AATSC6p', 'AATSC7p', 'AATSC8p', 'AATSC0i', 'AATSC1i', 'AATSC2i', 'AATSC3i', 'AATSC4i', 'AATSC5i', 'AATSC6i', 'AATSC7i', 'AATSC8i', 'AATSC0s', 'AATSC1s', 'AATSC2s', 'AATSC3s', 'AATSC4s', 'AATSC5s', 'AATSC6s', 'AATSC7s', 'AATSC8s', 'MATS1c', 'MATS2c', 'MATS3c', 'MATS4c', 'MATS5c', 'MATS6c', 'MATS7c', 'MATS8c', 'MATS1m', 'MATS2m', 'MATS3m', 'MATS4m', 'MATS5m', 'MATS6m', 'MATS7m', 'MATS8m', 'MATS1v', 'MATS2v', 'MATS3v', 'MATS4v', 'MATS5v', 'MATS6v', 'MATS7v', 'MATS8v', 'MATS1e', 'MATS2e', 'MATS3e', 'MATS4e', 'MATS5e', 'MATS6e', 'MATS7e', 'MATS8e', 'MATS1p', 'MATS2p', 'MATS3p', 'MATS4p', 'MATS5p', 'MATS6p', 'MATS7p', 'MATS8p', 'MATS1i', 'MATS2i', 'MATS3i', 'MATS4i', 'MATS5i', 'MATS6i', 'MATS7i', 'MATS8i', 'MATS1s', 'MATS2s', 'MATS3s', 'MATS4s', 'MATS5s', 'MATS6s', 'MATS7s', 'MATS8s', 'GATS1c', 'GATS2c', 'GATS3c', 'GATS4c', 'GATS5c', 'GATS6c', 'GATS7c', 'GATS8c', 'GATS1m', 'GATS2m', 'GATS3m', 'GATS4m', 'GATS5m', 'GATS6m', 'GATS7m', 'GATS8m', 'GATS1v', 'GATS2v', 'GATS3v', 'GATS4v', 'GATS5v', 'GATS6v', 'GATS7v', 'GATS8v', 'GATS1e', 'GATS2e', 'GATS3e', 'GATS4e', 'GATS5e', 'GATS6e', 'GATS7e', 'GATS8e', 'GATS1p', 'GATS2p', 'GATS3p', 'GATS4p', 'GATS5p', 'GATS6p', 'GATS7p', 'GATS8p', 'GATS1i', 'GATS2i', 'GATS3i', 'GATS4i', 'GATS5i', 'GATS6i', 'GATS7i', 'GATS8i', 'GATS1s', 'GATS2s', 'GATS3s', 'GATS4s', 'GATS5s', 'GATS6s', 'GATS7s', 'GATS8s', 'SpAbs_DzZ', 'SpMax_DzZ', 'SpDiam_DzZ', 'SpAD_DzZ', 'SpMAD_DzZ', 'EE_DzZ', 'SM1_DzZ', 'VE1_DzZ', 'VE2_DzZ', 'VE3_DzZ', 'VR1_DzZ', 'VR2_DzZ', 'VR3_DzZ', 'SpAbs_Dzm', 'SpMax_Dzm', 'SpDiam_Dzm', 'SpAD_Dzm', 'SpMAD_Dzm', 'EE_Dzm', 'SM1_Dzm', 'VE1_Dzm', 'VE2_Dzm', 'VE3_Dzm', 'VR1_Dzm', 'VR2_Dzm', 'VR3_Dzm', 'SpAbs_Dzv', 'SpMax_Dzv', 'SpDiam_Dzv', 'SpAD_Dzv', 'SpMAD_Dzv', 'EE_Dzv', 'SM1_Dzv', 'VE1_Dzv', 'VE2_Dzv', 'VE3_Dzv', 'VR1_Dzv', 'VR2_Dzv', 'VR3_Dzv', 'SpAbs_Dze', 'SpMax_Dze', 'SpDiam_Dze', 'SpAD_Dze', 'SpMAD_Dze', 'EE_Dze', 'SM1_Dze', 'VE1_Dze', 'VE2_Dze', 'VE3_Dze', 'VR1_Dze', 'VR2_Dze', 'VR3_Dze', 'SpAbs_Dzp', 'SpMax_Dzp', 'SpDiam_Dzp', 'SpAD_Dzp', 'SpMAD_Dzp', 'EE_Dzp', 'SM1_Dzp', 'VE1_Dzp', 'VE2_Dzp', 'VE3_Dzp', 'VR1_Dzp', 'VR2_Dzp', 'VR3_Dzp', 'SpAbs_Dzi', 'SpMax_Dzi', 'SpDiam_Dzi', 'SpAD_Dzi', 'SpMAD_Dzi', 'EE_Dzi', 'SM1_Dzi', 'VE1_Dzi', 'VE2_Dzi', 'VE3_Dzi', 'VR1_Dzi', 'VR2_Dzi', 'VR3_Dzi', 'SpAbs_Dzs', 'SpMax_Dzs', 'SpDiam_Dzs', 'SpAD_Dzs', 'SpMAD_Dzs', 'EE_Dzs', 'SM1_Dzs', 'VE1_Dzs', 'VE2_Dzs', 'VE3_Dzs', 'VR1_Dzs', 'VR2_Dzs', 'VR3_Dzs', 'nBase', 'BCUTw-1l', 'BCUTw-1h', 'BCUTc-1l', 'BCUTc-1h', 'BCUTp-1l', 'BCUTp-1h', 'nBonds', 'nBonds2', 'nBondsS', 'nBondsS2', 'nBondsS3', 'nBondsD', 'nBondsD2', 'nBondsT', 'nBondsM', 'bpol', 'SpMax1_Bhm', 'SpMax2_Bhm', 'SpMax3_Bhm', 'SpMax4_Bhm', 'SpMax5_Bhm', 'SpMax6_Bhm', 'SpMax7_Bhm', 'SpMax8_Bhm', 'SpMin1_Bhm', 'SpMin2_Bhm', 'SpMin3_Bhm', 'SpMin4_Bhm', 'SpMin5_Bhm', 'SpMin6_Bhm', 'SpMin7_Bhm', 'SpMin8_Bhm', 'SpMax1_Bhv', 'SpMax2_Bhv', 'SpMax3_Bhv', 'SpMax4_Bhv', 'SpMax5_Bhv', 'SpMax6_Bhv', 'SpMax7_Bhv', 'SpMax8_Bhv', 'SpMin1_Bhv', 'SpMin2_Bhv', 'SpMin3_Bhv', 'SpMin4_Bhv', 'SpMin5_Bhv', 'SpMin6_Bhv', 'SpMin7_Bhv', 'SpMin8_Bhv', 'SpMax1_Bhe', 'SpMax2_Bhe', 'SpMax3_Bhe', 'SpMax4_Bhe', 'SpMax5_Bhe', 'SpMax6_Bhe', 'SpMax7_Bhe', 'SpMax8_Bhe', 'SpMin1_Bhe', 'SpMin2_Bhe', 'SpMin3_Bhe', 'SpMin4_Bhe', 'SpMin5_Bhe', 'SpMin6_Bhe', 'SpMin7_Bhe', 'SpMin8_Bhe', 'SpMax1_Bhp', 'SpMax2_Bhp', 'SpMax3_Bhp', 'SpMax4_Bhp', 'SpMax5_Bhp', 'SpMax6_Bhp', 'SpMax7_Bhp', 'SpMax8_Bhp', 'SpMin1_Bhp', 'SpMin2_Bhp', 'SpMin3_Bhp', 'SpMin4_Bhp', 'SpMin5_Bhp', 'SpMin6_Bhp', 'SpMin7_Bhp', 'SpMin8_Bhp', 'SpMax1_Bhi', 'SpMax2_Bhi', 'SpMax3_Bhi', 'SpMax4_Bhi', 'SpMax5_Bhi', 'SpMax6_Bhi', 'SpMax7_Bhi', 'SpMax8_Bhi', 'SpMin1_Bhi', 'SpMin2_Bhi', 'SpMin3_Bhi', 'SpMin4_Bhi', 'SpMin5_Bhi', 'SpMin6_Bhi', 'SpMin7_Bhi', 'SpMin8_Bhi', 'SpMax1_Bhs', 'SpMax2_Bhs', 'SpMax3_Bhs', 'SpMax4_Bhs', 'SpMax5_Bhs', 'SpMax6_Bhs', 'SpMax7_Bhs', 'SpMax8_Bhs', 'SpMin1_Bhs', 'SpMin2_Bhs', 'SpMin3_Bhs', 'SpMin4_Bhs', 'SpMin5_Bhs', 'SpMin6_Bhs', 'SpMin7_Bhs', 'SpMin8_Bhs', 'C1SP1', 'C2SP1', 'C1SP2', 'C2SP2', 'C3SP2', 'C1SP3', 'C2SP3', 'C3SP3', 'C4SP3', 'SCH-3', 'SCH-4', 'SCH-5', 'SCH-6', 'SCH-7', 'VCH-3', 'VCH-4', 'VCH-5', 'VCH-6', 'VCH-7', 'SC-3', 'SC-4', 'SC-5', 'SC-6', 'VC-3', 'VC-4', 'VC-5', 'VC-6', 'SPC-4', 'SPC-5', 'SPC-6', 'VPC-4', 'VPC-5', 'VPC-6', 'SP-0', 'SP-1', 'SP-2', 'SP-3', 'SP-4', 'SP-5', 'SP-6', 'SP-7', 'ASP-0', 'ASP-1', 'ASP-2', 'ASP-3', 'ASP-4', 'ASP-5', 'ASP-6', 'ASP-7', 'VP-0', 'VP-1', 'VP-2', 'VP-3', 'VP-4', 'VP-5', 'VP-6', 'VP-7', 'AVP-0', 'AVP-1', 'AVP-2', 'AVP-3', 'AVP-4', 'AVP-5', 'AVP-6', 'AVP-7', 'Sv', 'Sse', 'Spe', 'Sare', 'Sp', 'Si', 'Mv', 'Mse', 'Mpe', 'Mare', 'Mp', 'Mi', 'CrippenLogP', 'CrippenMR', 'SpMax_Dt', 'SpDiam_Dt', 'SpAD_Dt', 'SpMAD_Dt', 'EE_Dt', 'VE1_Dt', 'VE2_Dt', 'VE3_Dt', 'VR1_Dt', 'VR2_Dt', 'VR3_Dt', 'ECCEN', 'nHBd', 'nwHBd', 'nHBa', 'nwHBa', 'nHBint2', 'nHBint3', 'nHBint4', 'nHBint5', 'nHBint6', 'nHBint7', 'nHBint8', 'nHBint9', 'nHBint10', 'nHsOH', 'nHdNH', 'nHsSH', 'nHsNH2', 'nHssNH', 'nHaaNH', 'nHsNH3p', 'nHssNH2p', 'nHsssNHp', 'nHtCH', 'nHdCH2', 'nHdsCH', 'nHaaCH', 'nHCHnX', 'nHCsats', 'nHCsatu', 'nHAvin', 'nHother', 'nsCH3', 'ndCH2', 'nssCH2', 'ntCH', 'ndsCH', 'naaCH', 'nsssCH', 'ntsC', 'ndssC', 'naasC', 'naaaC', 'nssssC', 'nsNH3p', 'nsNH2', 'nssNH2p', 'ndNH', 'nssNH', 'naaNH', 'ntN', 'nsssNHp', 'ndsN', 'naaN', 'nsssN', 'naasN', 'nssssNp', 'nsOH', 'ndO', 'nssO', 'naaO', 'nsOm', 'nsF', 'ndsssP', 'nsSH', 'ndS', 'nssS', 'naaS', 'ndssS', 'nddssS', 'nsCl', 'nsBr', 'nsI', 'SHBd', 'SwHBd', 'SHBa', 'SwHBa', 'SHBint2', 'SHBint3', 'SHBint4', 'SHBint5', 'SHBint6', 'SHBint7', 'SHBint8', 'SHBint9', 'SHBint10', 'SHsOH', 'SHdNH', 'SHsSH', 'SHsNH2', 'SHssNH', 'SHaaNH', 'SHsNH3p', 'SHssNH2p', 'SHsssNHp', 'SHtCH', 'SHdCH2', 'SHdsCH', 'SHaaCH', 'SHCHnX', 'SHCsats', 'SHCsatu', 'SHAvin', 'SHother', 'SsCH3', 'SdCH2', 'SssCH2', 'StCH', 'SdsCH', 'SaaCH', 'SsssCH', 'StsC', 'SdssC', 'SaasC', 'SaaaC', 'SssssC', 'SsNH3p', 'SsNH2', 'SssNH2p', 'SdNH', 'SssNH', 'SaaNH', 'StN', 'SsssNHp', 'SdsN', 'SaaN', 'SsssN', 'SaasN', 'SssssNp', 'SsOH', 'SdO', 'SssO', 'SaaO', 'SsOm', 'SsF', 'SdsssP', 'SsSH', 'SdS', 'SssS', 'SaaS', 'SdssS', 'SddssS', 'SsCl', 'SsBr', 'SsI', 'minHBd', 'minwHBd', 'minHBa', 'minwHBa', 'minHBint2', 'minHBint3', 'minHBint4', 'minHBint5', 'minHBint6', 'minHBint7', 'minHBint8', 'minHBint9', 'minHBint10', 'minHsOH', 'minHdNH', 'minHsSH', 'minHsNH2', 'minHssNH', 'minHaaNH', 'minHsNH3p', 'minHssNH2p', 'minHsssNHp', 'minHtCH', 'minHdCH2', 'minHdsCH', 'minHaaCH', 'minHCHnX', 'minHCsats', 'minHCsatu', 'minHAvin', 'minHother', 'minsCH3', 'mindCH2', 'minssCH2', 'mintCH', 'mindsCH', 'minaaCH', 'minsssCH', 'mintsC', 'mindssC', 'minaasC', 'minaaaC', 'minssssC', 'minsNH3p', 'minsNH2', 'minssNH2p', 'mindNH', 'minssNH', 'minaaNH', 'mintN', 'minsssNHp', 'mindsN', 'minaaN', 'minsssN', 'minaasN', 'minssssNp', 'minsOH', 'mindO', 'minssO', 'minaaO', 'minsOm', 'minsF', 'mindsssP', 'minsSH', 'mindS', 'minssS', 'minaaS', 'mindssS', 'minddssS', 'minsCl', 'minsBr', 'minsI', 'maxHBd', 'maxwHBd', 'maxHBa', 'maxwHBa', 'maxHBint2', 'maxHBint3', 'maxHBint4', 'maxHBint5', 'maxHBint6', 'maxHBint7', 'maxHBint8', 'maxHBint9', 'maxHBint10', 'maxHsOH', 'maxHdNH', 'maxHsSH', 'maxHsNH2', 'maxHssNH', 'maxHaaNH', 'maxHsNH3p', 'maxHssNH2p', 'maxHsssNHp', 'maxHtCH', 'maxHdCH2', 'maxHdsCH', 'maxHaaCH', 'maxHCHnX', 'maxHCsats', 'maxHCsatu', 'maxHAvin', 'maxHother', 'maxsCH3', 'maxdCH2', 'maxssCH2', 'maxtCH', 'maxdsCH', 'maxaaCH', 'maxsssCH', 'maxtsC', 'maxdssC', 'maxaasC', 'maxaaaC', 'maxssssC', 'maxsNH3p', 'maxsNH2', 'maxssNH2p', 'maxdNH', 'maxssNH', 'maxaaNH', 'maxtN', 'maxsssNHp', 'maxdsN', 'maxaaN', 'maxsssN', 'maxaasN', 'maxssssNp', 'maxsOH', 'maxdO', 'maxssO', 'maxaaO', 'maxsOm', 'maxsF', 'maxsSH', 'maxdS', 'maxsCl', 'maxsBr', 'maxsI', 'sumI', 'meanI', 'hmax', 'gmax', 'hmin', 'gmin', 'LipoaffinityIndex', 'MAXDN', 'MAXDP', 'DELS', 'MAXDN2', 'MAXDP2', 'DELS2', 'ETA_Alpha', 'ETA_AlphaP', 'ETA_dAlpha_A', 'ETA_dAlpha_B', 'ETA_Epsilon_1', 'ETA_Epsilon_2', 'ETA_Epsilon_3', 'ETA_Epsilon_4', 'ETA_Epsilon_5', 'ETA_dEpsilon_A', 'ETA_dEpsilon_B', 'ETA_dEpsilon_C', 'ETA_dEpsilon_D', 'ETA_Psi_1', 'ETA_dPsi_A', 'ETA_dPsi_B', 'ETA_Shape_P', 'ETA_Shape_Y', 'ETA_Shape_X', 'ETA_Beta', 'ETA_BetaP', 'ETA_Beta_s', 'ETA_BetaP_s', 'ETA_Beta_ns', 'ETA_BetaP_ns', 'ETA_dBeta', 'ETA_dBetaP', 'ETA_Beta_ns_d', 'ETA_BetaP_ns_d', 'ETA_Eta', 'ETA_EtaP', 'ETA_Eta_R', 'ETA_Eta_F', 'ETA_EtaP_F', 'ETA_Eta_L', 'ETA_EtaP_L', 'ETA_Eta_R_L', 'ETA_Eta_F_L', 'ETA_EtaP_F_L', 'ETA_Eta_B', 'ETA_EtaP_B', 'ETA_Eta_B_RC', 'ETA_EtaP_B_RC', 'FMF', 'fragC', 'nHBAcc', 'nHBAcc2', 'nHBAcc3', 'nHBAcc_Lipinski', 'nHBDon', 'nHBDon_Lipinski', 'HybRatio', 'IC0', 'IC1', 'IC2', 'IC3', 'IC4', 'IC5', 'TIC0', 'TIC1', 'TIC2', 'TIC3', 'TIC4', 'TIC5', 'SIC0', 'SIC1', 'SIC2', 'SIC3', 'SIC4', 'SIC5', 'CIC0', 'CIC1', 'CIC2', 'CIC3', 'CIC4', 'CIC5', 'BIC0', 'BIC1', 'BIC2', 'BIC3', 'BIC4', 'BIC5', 'MIC0', 'MIC1', 'MIC2', 'MIC3', 'MIC4', 'MIC5', 'ZMIC0', 'ZMIC1', 'ZMIC2', 'ZMIC3', 'ZMIC4', 'ZMIC5', 'Kier1', 'Kier2', 'Kier3', 'nAtomLC', 'nAtomP', 'nAtomLAC', 'MLogP', 'McGowan_Volume', 'MDEC-11', 'MDEC-12', 'MDEC-13', 'MDEC-14', 'MDEC-22', 'MDEC-23', 'MDEC-24', 'MDEC-33', 'MDEC-34', 'MDEC-44', 'MDEO-11', 'MDEO-12', 'MDEO-22', 'MDEN-11', 'MDEN-12', 'MDEN-13', 'MDEN-22', 'MDEN-23', 'MDEN-33', 'MLFER_A', 'MLFER_BH', 'MLFER_BO', 'MLFER_S', 'MLFER_E', 'MLFER_L', 'MPC2', 'MPC3', 'MPC4', 'MPC5', 'MPC6', 'MPC7', 'MPC8', 'MPC9', 'MPC10', 'TPC', 'piPC1', 'piPC2', 'piPC3', 'piPC4', 'piPC5', 'piPC6', 'piPC7', 'piPC8', 'piPC9', 'piPC10', 'TpiPC', 'R_TpiPCTPC', 'PetitjeanNumber', 'nRing', 'n3Ring', 'n4Ring', 'n5Ring', 'n6Ring', 'n7Ring', 'n8Ring', 'n12Ring', 'nFRing', 'nF6Ring', 'nF7Ring', 'nF8Ring', 'nF9Ring', 'nF10Ring', 'nF11Ring', 'nF12Ring', 'nFG12Ring', 'nTRing', 'nT4Ring', 'nT5Ring', 'nT6Ring', 'nT7Ring', 'nT8Ring', 'nT9Ring', 'nT10Ring', 'nT11Ring', 'nT12Ring', 'nTG12Ring', 'nHeteroRing', 'n3HeteroRing', 'n4HeteroRing', 'n5HeteroRing', 'n6HeteroRing', 'n7HeteroRing', 'n8HeteroRing', 'n12HeteroRing', 'nF6HeteroRing', 'nF7HeteroRing', 'nF8HeteroRing', 'nF9HeteroRing', 'nF10HeteroRing', 'nF11HeteroRing', 'nF12HeteroRing', 'nFG12HeteroRing', 'nT4HeteroRing', 'nT5HeteroRing', 'nT6HeteroRing', 'nT7HeteroRing', 'nT8HeteroRing', 'nT9HeteroRing', 'nT10HeteroRing', 'nT11HeteroRing', 'nT12HeteroRing', 'nTG12HeteroRing', 'nRotB', 'RotBFrac', 'nRotBt', 'RotBtFrac', 'LipinskiFailures', 'topoRadius', 'topoDiameter', 'topoShape', 'GGI1', 'GGI2', 'GGI3', 'GGI4', 'GGI5', 'GGI6', 'GGI7', 'GGI8', 'GGI9', 'GGI10', 'JGI1', 'JGI2', 'JGI3', 'JGI4', 'JGI5', 'JGI6', 'JGI7', 'JGI8', 'JGI9', 'JGI10', 'JGT', 'SpMax_D', 'SpDiam_D', 'SpAD_D', 'SpMAD_D', 'EE_D', 'VE1_D', 'VE2_D', 'VE3_D', 'VR1_D', 'VR2_D', 'VR3_D', 'TopoPSA', 'VABC', 'VAdjMat', 'MWC2', 'MWC3', 'MWC4', 'MWC5', 'MWC6', 'MWC7', 'MWC8', 'MWC9', 'MWC10', 'TWC', 'SRW2', 'SRW3', 'SRW4', 'SRW5', 'SRW6', 'SRW7', 'SRW8', 'SRW9', 'SRW10', 'TSRW', 'MW', 'AMW', 'WTPT-1', 'WTPT-2', 'WTPT-3', 'WTPT-4', 'WTPT-5', 'WPATH', 'WPOL', 'XLogP', 'Zagreb', 'Label']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()\n",
    "\n",
    "# Set a threshold for high correlation (e.g., 0.9)\n",
    "threshold = 0.9\n",
    "high_corr_vars = [column for column in correlation_matrix.columns if any(correlation_matrix[column] > threshold)]\n",
    "\n",
    "# Drop highly correlated columns\n",
    "df_reduced = df.drop(columns=high_corr_vars)\n",
    "\n",
    "print(f\"Dropped columns with high correlation: {high_corr_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f42ee661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nB</th>\n",
       "      <th>nBondsQ</th>\n",
       "      <th>nHmisc</th>\n",
       "      <th>nsLi</th>\n",
       "      <th>nssBe</th>\n",
       "      <th>nssssBem</th>\n",
       "      <th>nsBH2</th>\n",
       "      <th>nssBH</th>\n",
       "      <th>nsssB</th>\n",
       "      <th>...</th>\n",
       "      <th>nF4Ring</th>\n",
       "      <th>nF5Ring</th>\n",
       "      <th>n9HeteroRing</th>\n",
       "      <th>n10HeteroRing</th>\n",
       "      <th>n11HeteroRing</th>\n",
       "      <th>nG12HeteroRing</th>\n",
       "      <th>nFHeteroRing</th>\n",
       "      <th>nF4HeteroRing</th>\n",
       "      <th>nF5HeteroRing</th>\n",
       "      <th>nTHeteroRing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOGEN_smiles_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTOGEN_smiles_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTOGEN_smiles_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTOGEN_smiles_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOGEN_smiles_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ZINC000000001534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>ZINC000000001536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>ZINC000000001553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>ZINC000000001557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>ZINC000000001569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>952 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  nB  nBondsQ  nHmisc  nsLi  nssBe  nssssBem  nsBH2  \\\n",
       "0    AUTOGEN_smiles_1   0        0       0     0      0         0      0   \n",
       "1    AUTOGEN_smiles_2   0        0       0     0      0         0      0   \n",
       "2    AUTOGEN_smiles_3   0        0       0     0      0         0      0   \n",
       "3    AUTOGEN_smiles_4   0        0       0     0      0         0      0   \n",
       "4    AUTOGEN_smiles_5   0        0       0     0      0         0      0   \n",
       "..                ...  ..      ...     ...   ...    ...       ...    ...   \n",
       "947  ZINC000000001534   0        0       0     0      0         0      0   \n",
       "948  ZINC000000001536   0        0       0     0      0         0      0   \n",
       "949  ZINC000000001553   0        0       0     0      0         0      0   \n",
       "950  ZINC000000001557   0        0       0     0      0         0      0   \n",
       "951  ZINC000000001569   0        0       0     0      0         0      0   \n",
       "\n",
       "     nssBH  nsssB  ...  nF4Ring  nF5Ring  n9HeteroRing  n10HeteroRing  \\\n",
       "0        0      0  ...        0        0             0              0   \n",
       "1        0      0  ...        0        0             0              0   \n",
       "2        0      0  ...        0        0             0              0   \n",
       "3        0      0  ...        0        0             0              0   \n",
       "4        0      0  ...        0        0             0              0   \n",
       "..     ...    ...  ...      ...      ...           ...            ...   \n",
       "947      0      0  ...        0        0             0              0   \n",
       "948      0      0  ...        0        0             0              0   \n",
       "949      0      0  ...        0        0             0              0   \n",
       "950      0      0  ...        0        0             0              0   \n",
       "951      0      0  ...        0        0             0              0   \n",
       "\n",
       "     n11HeteroRing  nG12HeteroRing  nFHeteroRing  nF4HeteroRing  \\\n",
       "0                0               0             0              0   \n",
       "1                0               0             0              0   \n",
       "2                0               0             0              0   \n",
       "3                0               0             0              0   \n",
       "4                0               0             0              0   \n",
       "..             ...             ...           ...            ...   \n",
       "947              0               0             0              0   \n",
       "948              0               0             0              0   \n",
       "949              0               0             0              0   \n",
       "950              0               0             0              0   \n",
       "951              0               0             0              0   \n",
       "\n",
       "     nF5HeteroRing  nTHeteroRing  \n",
       "0                0             0  \n",
       "1                0             0  \n",
       "2                0             0  \n",
       "3                0             0  \n",
       "4                0             0  \n",
       "..             ...           ...  \n",
       "947              0             0  \n",
       "948              0             0  \n",
       "949              0             0  \n",
       "950              0             0  \n",
       "951              0             0  \n",
       "\n",
       "[952 rows x 210 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5922db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 572 highly correlated columns.\n"
     ]
    }
   ],
   "source": [
    "label_col = 'Label'  # change this if your label column has a different name\n",
    "\n",
    "\n",
    "# Separate features and label\n",
    "X = df.drop(columns=[label_col])\n",
    "y = df[label_col]\n",
    "\n",
    "# Keep only numeric columns for correlation filtering\n",
    "X_numeric = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_numeric.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop highly correlated features (correlation > 0.95)\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "print(f\"Dropping {len(to_drop)} highly correlated columns.\")\n",
    "\n",
    "# Drop correlated features from the original X (to preserve any remaining non-numeric features, if needed)\n",
    "X_filtered = X.drop(columns=to_drop)\n",
    "\n",
    "# Recombine with label column\n",
    "data_cleaned = pd.concat([X_filtered, y], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7ca330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned\n",
    "data_cleaned.to_csv(\"filtered_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5686bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_cleaned.drop(columns=[label_col])\n",
    "y = data_cleaned[label_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81159e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns (except the label)\n",
    "non_numeric_cols = data_cleaned.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "non_numeric_cols = [col for col in non_numeric_cols if col != label_col]\n",
    "\n",
    "# Drop those columns\n",
    "data_cleaned = data_cleaned.drop(columns=non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844d9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels again\n",
    "X = data_cleaned.drop(columns=[label_col])\n",
    "y = data_cleaned[label_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "602d2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a0e17ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 81   0]\n",
      " [  6 104]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        81\n",
      "           1       1.00      0.95      0.97       110\n",
      "\n",
      "    accuracy                           0.97       191\n",
      "   macro avg       0.97      0.97      0.97       191\n",
      "weighted avg       0.97      0.97      0.97       191\n",
      "\n",
      "Accuracy: 0.9685863874345549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3c073b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a23e1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "Confusion Matrix:\n",
      " [[ 80   1]\n",
      " [  6 104]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        81\n",
      "           1       0.99      0.95      0.97       110\n",
      "\n",
      "    accuracy                           0.96       191\n",
      "   macro avg       0.96      0.97      0.96       191\n",
      "weighted avg       0.96      0.96      0.96       191\n",
      "\n",
      "Accuracy: 0.9633507853403142\n",
      "\n",
      "=== SVM ===\n",
      "Confusion Matrix:\n",
      " [[  4  77]\n",
      " [  0 110]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09        81\n",
      "           1       0.59      1.00      0.74       110\n",
      "\n",
      "    accuracy                           0.60       191\n",
      "   macro avg       0.79      0.52      0.42       191\n",
      "weighted avg       0.76      0.60      0.47       191\n",
      "\n",
      "Accuracy: 0.5968586387434555\n",
      "\n",
      "=== XGBoost ===\n",
      "Confusion Matrix:\n",
      " [[ 80   1]\n",
      " [  3 107]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98        81\n",
      "           1       0.99      0.97      0.98       110\n",
      "\n",
      "    accuracy                           0.98       191\n",
      "   macro avg       0.98      0.98      0.98       191\n",
      "weighted avg       0.98      0.98      0.98       191\n",
      "\n",
      "Accuracy: 0.9790575916230366\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Confusion Matrix:\n",
      " [[ 77   4]\n",
      " [  6 104]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        81\n",
      "           1       0.96      0.95      0.95       110\n",
      "\n",
      "    accuracy                           0.95       191\n",
      "   macro avg       0.95      0.95      0.95       191\n",
      "weighted avg       0.95      0.95      0.95       191\n",
      "\n",
      "Accuracy: 0.9476439790575916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress convergence warnings for clean output\n",
    "\n",
    "# Step 1: Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Step 2: Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Step 3: Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76b999",
   "metadata": {},
   "source": [
    "Here’s a table summarizing the results for your markdown:\n",
    "\n",
    "| **Model**            | **Accuracy**  | **Precision (Class 0)** | **Precision (Class 1)** | **Recall (Class 0)** | **Recall (Class 1)** | **F1-Score (Class 0)** | **F1-Score (Class 1)** | **Macro Avg F1-Score** | **Weighted Avg F1-Score** | **Confusion Matrix**              |\n",
    "|----------------------|---------------|-------------------------|-------------------------|----------------------|----------------------|------------------------|------------------------|------------------------|---------------------------|-----------------------------------|\n",
    "| **Random Forest**     | 96.3%         | 0.93                    | 0.99                    | 0.99                 | 0.95                 | 0.96                   | 0.97                   | 0.96                   | 0.96                      | [[80, 1], [6, 104]]               |\n",
    "| **Support Vector Machine** | 59.7%         | 1.00                    | 0.59                    | 0.05                 | 1.00                 | 0.09                   | 0.74                   | 0.42                   | 0.47                      | [[4, 77], [0, 110]]               |\n",
    "| **XGBoost**           | 97.9%         | 0.96                    | 0.99                    | 0.99                 | 0.97                 | 0.98                   | 0.98                   | 0.98                   | 0.98                      | [[80, 1], [3, 107]]               |\n",
    "| **Logistic Regression** | 94.8%         | 0.93                    | 0.96                    | 0.95                 | 0.95                 | 0.94                   | 0.95                   | 0.95                   | 0.95                      | [[77, 4], [6, 104]]               |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37043185",
   "metadata": {},
   "source": [
    "Hybrid Model (Random Forest + XGBoost) for enhanced prediction using stacking, where the predcitions are combined using a logistic regression model as a meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9ffbddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972027972027972\n",
      "Confusion Matrix:\n",
      "[[115   4]\n",
      " [  4 163]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       119\n",
      "           1       0.98      0.98      0.98       167\n",
      "\n",
      "    accuracy                           0.97       286\n",
      "   macro avg       0.97      0.97      0.97       286\n",
      "weighted avg       0.97      0.97      0.97       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "df_cleaned = pd.read_csv(\"filtered_data.csv\")\n",
    "X_data = data_cleaned.drop(columns=[label_col])\n",
    "y_data = data_cleaned[label_col]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize individual classifiers\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Initialize the meta-classifier (Logistic Regression in this case)\n",
    "meta_classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create the hybrid model using stacking\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb)],\n",
    "    final_estimator=meta_classifier\n",
    ")\n",
    "\n",
    "# Train the hybrid model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedee390",
   "metadata": {},
   "source": [
    "Here's a table summarizing all the results for you to add to your markdown:\n",
    "\n",
    "| Model                | Accuracy  | Precision (Class 0) | Precision (Class 1) | Recall (Class 0) | Recall (Class 1) | F1-score (Class 0) | F1-score (Class 1) | Macro Average | Weighted Average |\n",
    "|----------------------|-----------|---------------------|---------------------|------------------|------------------|-------------------|-------------------|----------------|------------------|\n",
    "| **Hybrid Model**      | 97.2%     | 0.97                | 0.98                | 0.97             | 0.98             | 0.97              | 0.98              | 0.97           | 0.97             |\n",
    "| **XGBoost**           | 97.9%     | 0.96                | 0.99                | 0.99             | 0.97             | 0.98              | 0.98              | 0.98           | 0.98             |\n",
    "| **Random Forest**     | 96.3%     | 0.93                | 0.99                | 0.99             | 0.95             | 0.96              | 0.97              | 0.96           | 0.96             |\n",
    "| **Logistic Regression** | 94.8%    | 0.93                | 0.96                | 0.95             | 0.95             | 0.94              | 0.95              | 0.95           | 0.95             |\n",
    "| **SVM**               | 59.7%     | 1.00                | 0.59                | 0.05             | 1.00             | 0.09              | 0.74              | 0.79           | 0.60             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040598d7",
   "metadata": {},
   "source": [
    "For AI-driven drug disovery precision and recall of Class 1 is crucial. Based on our model performance we shall select **XGBoost** as our strongest choice. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
